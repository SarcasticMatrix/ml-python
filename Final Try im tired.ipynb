{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, roc_auc_score,accuracy_score\n",
    "df = pd.read_csv('models/data/data.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "class DataPreparer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.cols_num = None\n",
    "        self.cols_cat = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = X.drop(columns=['duration'])    \n",
    "        self.cols_num = X.select_dtypes(include=['number']).columns.tolist()\n",
    "        self.cols_cat = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        if 'y' in self.cols_cat:\n",
    "            self.cols_cat.remove('y')\n",
    "        if \"y\" in self.cols_num:\n",
    "            self.cols_num.remove(\"y\")\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Create dummy variables for categorical columns\n",
    "        X = pd.concat([X, pd.get_dummies(X[self.cols_cat], drop_first=False)], axis=1)\n",
    "        # Create the output label\n",
    "        X['OUTPUT_LABEL'] = (X['y'] == 'yes').astype(int)\n",
    "        # Define the input columns\n",
    "        cols_input = self.cols_num + list(pd.get_dummies(X[self.cols_cat], drop_first=False).columns)\n",
    "        # Return the prepared data\n",
    "        scaler = StandardScaler()\n",
    "        economic_factors = X[['cons.price.idx', 'cons.conf.idx', 'emp.var.rate','euribor3m', 'nr.employed']]\n",
    "        economic_factors_scaled = scaler.fit_transform(economic_factors)\n",
    "\n",
    "        pca = PCA(n_components=1)\n",
    "        principal_components = pca.fit_transform(economic_factors_scaled)\n",
    "\n",
    "\n",
    "        X['Econ.Stab.Sent.PCA']=principal_components[:,0]\n",
    "\n",
    "        X = X.drop(['cons.price.idx', 'emp.var.rate', 'euribor3m', 'nr.employed'], axis=1)\n",
    "        for col in ['cons.price.idx', 'emp.var.rate', 'euribor3m', 'nr.employed']:\n",
    "            if col in cols_input:\n",
    "                cols_input.remove(col)\n",
    "        cols_input += ['Econ.Stab.Sent.PCA']\n",
    "        return X[cols_input + ['OUTPUT_LABEL']]\n",
    "\n",
    "# Example usage\n",
    "df = pd.read_csv('models/data/data.csv', sep=';')\n",
    "data_preparer = DataPreparer()\n",
    "df_data = data_preparer.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_data.sample(n = len(df_data), random_state = 2024)\n",
    "df_data = df_data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train_all, df_valid_test = train_test_split(df_data, test_size=0.30, random_state=42)\n",
    "df_valid, df_test = train_test_split(df_valid_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "\n",
    "# Function to balance the dataset using RandomUnderSampler\n",
    "def balance_data(df,balancer_type='SMOTE'):\n",
    "    X = df.drop(columns=[\"OUTPUT_LABEL\"])\n",
    "    y = df[\"OUTPUT_LABEL\"]\n",
    "    \n",
    "    if balancer_type == 'SMOTE':\n",
    "        balancer = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "    elif balancer_type == 'RandomUnderSampler':\n",
    "        balancer = RandomUnderSampler(sampling_strategy=1.0, random_state=42)\n",
    "    elif balancer_type == 'EditedNearestNeighbours':\n",
    "        balancer = EditedNearestNeighbours(sampling_strategy='auto', n_neighbors=3, kind_sel='all')\n",
    "    elif balancer_type == 'None':\n",
    "        return df\n",
    "    else:\n",
    "        raise ValueError(\"balancer_type must be 'SMOTE', 'RandomUnderSampler', or 'EditedNearestNeighbours'\")\n",
    "    \n",
    "    # X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "    # X_resampled, y_resampled = enn.fit_resample(X, y)\n",
    "    X_resampled, y_resampled = balancer.fit_resample(X, y)\n",
    "    \n",
    "    # Recombine the features and labels into a balanced DataFrame\n",
    "    df_resampled = pd.concat([pd.DataFrame(X_resampled, columns=X.columns), \n",
    "                              pd.DataFrame(y_resampled, columns=[\"OUTPUT_LABEL\"])], axis=1)\n",
    "    \n",
    "    # Shuffle the DataFrame\n",
    "    df_resampled = df_resampled.sample(n=len(df_resampled), random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    return df_resampled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resampling using smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Balance the training, validation, and test data\n",
    "df_train = balance_data(df_train_all)\n",
    "df_valid = balance_data(df_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input and output matrices\n",
    "X_train = df_train.drop(columns=[\"OUTPUT_LABEL\"]).values\n",
    "X_train_all = df_train_all.drop(columns=[\"OUTPUT_LABEL\"]).values\n",
    "X_valid = df_valid.drop(columns=[\"OUTPUT_LABEL\"]).values\n",
    "\n",
    "y_train = df_train['OUTPUT_LABEL'].values\n",
    "y_train_all = df_train_all['OUTPUT_LABEL'].values\n",
    "y_valid = df_valid['OUTPUT_LABEL'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_all)\n",
    "X_train_all_tf = scaler.transform(X_train_all)\n",
    "X_train_tf = scaler.transform(X_train)\n",
    "X_valid_tf = scaler.transform(X_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=2,\n",
       "                   estimator=GradientBoostingClassifier(learning_rate=1.0,\n",
       "                                                        random_state=42),\n",
       "                   n_iter=20,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [0.001, 0.01, 0.1],\n",
       "                                        &#x27;max_depth&#x27;: range(1, 5),\n",
       "                                        &#x27;n_estimators&#x27;: range(50, 200, 50)},\n",
       "                   random_state=42, scoring=make_scorer(roc_auc_score))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=2,\n",
       "                   estimator=GradientBoostingClassifier(learning_rate=1.0,\n",
       "                                                        random_state=42),\n",
       "                   n_iter=20,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [0.001, 0.01, 0.1],\n",
       "                                        &#x27;max_depth&#x27;: range(1, 5),\n",
       "                                        &#x27;n_estimators&#x27;: range(50, 200, 50)},\n",
       "                   random_state=42, scoring=make_scorer(roc_auc_score))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=1.0, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=1.0, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=2,\n",
       "                   estimator=GradientBoostingClassifier(learning_rate=1.0,\n",
       "                                                        random_state=42),\n",
       "                   n_iter=20,\n",
       "                   param_distributions={'learning_rate': [0.001, 0.01, 0.1],\n",
       "                                        'max_depth': range(1, 5),\n",
       "                                        'n_estimators': range(50, 200, 50)},\n",
       "                   random_state=42, scoring=make_scorer(roc_auc_score))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=3, random_state=42)\n",
    "gbc.fit(X_train_tf, y_train)\n",
    "\n",
    "random_grid_gbc = {\n",
    "    'n_estimators': range(50, 200, 50),\n",
    "    'max_depth': range(1, 5, 1),\n",
    "    'learning_rate': [0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "auc_scoring = make_scorer(roc_auc_score)\n",
    "gbc_random_smote = RandomizedSearchCV(estimator=gbc, param_distributions=random_grid_gbc, n_iter=20, cv=2, scoring=auc_scoring, verbose=0, random_state=42)\n",
    "gbc_random_smote.fit(X_train_tf, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train_preds_random = gbc_random_smote.best_estimator_.predict_proba(X_train_tf)[:, 1]\n",
    "y_valid_preds_random = gbc_random_smote.best_estimator_.predict_proba(X_valid_tf)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def print_report(y_actual, y_pred, thresh):\n",
    "    try:\n",
    "        auc = roc_auc_score(y_actual, y_pred)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        auc = -1\n",
    "    try:\n",
    "        accuracy = accuracy_score(y_actual, (y_pred > thresh))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        accuracy = -1\n",
    "    try:\n",
    "        recall = recall_score(y_actual, (y_pred > thresh))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        recall = -1\n",
    "    try:\n",
    "        precision = precision_score(y_actual, (y_pred > thresh))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        precision = -1\n",
    "    try:\n",
    "        f1 = np.divide(2 * (precision * recall), (precision + recall), out=np.zeros(1), where=(precision + recall) != 0)[0] if precision != -1 and recall != -1 else -1\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        f1 = -1\n",
    "    return auc, accuracy, recall, precision, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "thresh = 0.5\n",
    "train_report = print_report(y_train, y_train_preds_random, thresh)\n",
    "valid_report = print_report(y_valid, y_valid_preds_random, thresh)\n",
    "df_valid, df_test = train_test_split(df_valid_test, test_size=0.5, random_state=42)\n",
    "df_test = balance_data(df_test, balancer_type='SMOTE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Report:\n",
      "\t  AUC=0.975\n",
      "\t Accuracy=0.936\n",
      "\t Recall=0.907\n",
      "\t Precision=0.962\n",
      "\t F1=0.934\n",
      "Validation Report:\n",
      "\t  AUC=0.970\n",
      "\t Accuracy=0.935\n",
      "\t Recall=0.905\n",
      "\t Precision=0.963\n",
      "\t F1=0.933\n",
      "test dataframe has been resampled using the same method as the training data\n",
      "Test Report:\n",
      "\t  AUC=0.972\n",
      "\t Accuracy=0.932\n",
      "\t Recall=0.906\n",
      "\t Precision=0.956\n",
      "\t F1=0.930\n"
     ]
    }
   ],
   "source": [
    "X_test = df_test.drop(columns=[\"OUTPUT_LABEL\"]).values\n",
    "y_test = df_test['OUTPUT_LABEL'].values\n",
    "X_test_tf = scaler.transform(X_test)\n",
    "y_test_preds_random = gbc_random_smote.best_estimator_.predict_proba(X_test_tf)[:, 1]\n",
    "test_report = print_report(y_test, y_test_preds_random, thresh)\n",
    "\n",
    "\n",
    "print(f\"Training Report:\\n\\t  AUC={train_report[0]:.3f}\\n\\t Accuracy={train_report[1]:.3f}\\n\\t Recall={train_report[2]:.3f}\\n\\t Precision={train_report[3]:.3f}\\n\\t F1={train_report[4]:.3f}\")\n",
    "print(f\"Validation Report:\\n\\t  AUC={valid_report[0]:.3f}\\n\\t Accuracy={valid_report[1]:.3f}\\n\\t Recall={valid_report[2]:.3f}\\n\\t Precision={valid_report[3]:.3f}\\n\\t F1={valid_report[4]:.3f}\")\n",
    "print(\"test dataframe has been resampled using the same method as the training data\")\n",
    "print(f\"Test Report:\\n\\t  AUC={test_report[0]:.3f}\\n\\t Accuracy={test_report[1]:.3f}\\n\\t Recall={test_report[2]:.3f}\\n\\t Precision={test_report[3]:.3f}\\n\\t F1={test_report[4]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataframe has not been resampled\n",
      "Test Report:\n",
      "\t  AUC=0.801\n",
      "\t Accuracy=0.820\n",
      "\t Recall=0.660\n",
      "\t Precision=0.358\n",
      "\t F1=0.464\n"
     ]
    }
   ],
   "source": [
    "df_valid, df_test = train_test_split(df_valid_test, test_size=0.5, random_state=42)\n",
    "df_test = balance_data(df_test, balancer_type='None')\n",
    "print(\"Test dataframe has not been resampled\")\n",
    "X_test = df_test.drop(columns=[\"OUTPUT_LABEL\"]).values\n",
    "y_test = df_test['OUTPUT_LABEL'].values\n",
    "X_test_tf = scaler.transform(X_test)\n",
    "y_test_preds_random = gbc_random_smote.best_estimator_.predict_proba(X_test_tf)[:, 1]\n",
    "test_report = print_report(y_test, y_test_preds_random, thresh)\n",
    "print(f\"Test Report:\\n\\t  AUC={test_report[0]:.3f}\\n\\t Accuracy={test_report[1]:.3f}\\n\\t Recall={test_report[2]:.3f}\\n\\t Precision={test_report[3]:.3f}\\n\\t F1={test_report[4]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling using random undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Balance the training, validation, and test data\n",
    "df_train = balance_data(df_train_all, balancer_type='RandomUnderSampler')\n",
    "df_valid = balance_data(df_valid, balancer_type='RandomUnderSampler')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input and output matrices\n",
    "X_train = df_train.drop(columns=[\"OUTPUT_LABEL\"]).values\n",
    "X_train_all = df_train_all.drop(columns=[\"OUTPUT_LABEL\"]).values\n",
    "X_valid = df_valid.drop(columns=[\"OUTPUT_LABEL\"]).values\n",
    "\n",
    "y_train = df_train['OUTPUT_LABEL'].values\n",
    "y_train_all = df_train_all['OUTPUT_LABEL'].values\n",
    "y_valid = df_valid['OUTPUT_LABEL'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_all)\n",
    "X_train_all_tf = scaler.transform(X_train_all)\n",
    "X_train_tf = scaler.transform(X_train)\n",
    "X_valid_tf = scaler.transform(X_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=2,\n",
       "                   estimator=GradientBoostingClassifier(learning_rate=1.0,\n",
       "                                                        random_state=42),\n",
       "                   n_iter=20,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [0.001, 0.01, 0.1],\n",
       "                                        &#x27;max_depth&#x27;: range(1, 5),\n",
       "                                        &#x27;n_estimators&#x27;: range(50, 200, 50)},\n",
       "                   random_state=42, scoring=make_scorer(roc_auc_score))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=2,\n",
       "                   estimator=GradientBoostingClassifier(learning_rate=1.0,\n",
       "                                                        random_state=42),\n",
       "                   n_iter=20,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [0.001, 0.01, 0.1],\n",
       "                                        &#x27;max_depth&#x27;: range(1, 5),\n",
       "                                        &#x27;n_estimators&#x27;: range(50, 200, 50)},\n",
       "                   random_state=42, scoring=make_scorer(roc_auc_score))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=1.0, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=1.0, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=2,\n",
       "                   estimator=GradientBoostingClassifier(learning_rate=1.0,\n",
       "                                                        random_state=42),\n",
       "                   n_iter=20,\n",
       "                   param_distributions={'learning_rate': [0.001, 0.01, 0.1],\n",
       "                                        'max_depth': range(1, 5),\n",
       "                                        'n_estimators': range(50, 200, 50)},\n",
       "                   random_state=42, scoring=make_scorer(roc_auc_score))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=3, random_state=42)\n",
    "gbc.fit(X_train_tf, y_train)\n",
    "\n",
    "random_grid_gbc = {\n",
    "    'n_estimators': range(50, 200, 50),\n",
    "    'max_depth': range(1, 5, 1),\n",
    "    'learning_rate': [0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "auc_scoring = make_scorer(roc_auc_score)\n",
    "gbc_random_Rus = RandomizedSearchCV(estimator=gbc, param_distributions=random_grid_gbc, n_iter=20, cv=2, scoring=auc_scoring, verbose=0, random_state=42)\n",
    "gbc_random_Rus.fit(X_train_tf, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train_preds_random_Rus = gbc_random_Rus.best_estimator_.predict_proba(X_train_tf)[:, 1]\n",
    "y_valid_preds_random_Rus = gbc_random_Rus.best_estimator_.predict_proba(X_valid_tf)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "thresh = 0.5\n",
    "train_report = print_report(y_train, y_train_preds_random_Rus, thresh)\n",
    "valid_report = print_report(y_valid, y_valid_preds_random_Rus, thresh)\n",
    "df_valid, df_test = train_test_split(df_valid_test, test_size=0.5, random_state=42)\n",
    "df_test = balance_data(df_test, balancer_type='RandomUnderSampler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Report:\n",
      "\t  AUC=0.816\n",
      "\t Accuracy=0.751\n",
      "\t Recall=0.655\n",
      "\t Precision=0.811\n",
      "\t F1=0.725\n",
      "Validation Report:\n",
      "\t  AUC=0.781\n",
      "\t Accuracy=0.735\n",
      "\t Recall=0.646\n",
      "\t Precision=0.786\n",
      "\t F1=0.709\n",
      "test dataframe has been resampled using the same method as the training data\n",
      "Test Report:\n",
      "\t  AUC=0.800\n",
      "\t Accuracy=0.751\n",
      "\t Recall=0.660\n",
      "\t Precision=0.806\n",
      "\t F1=0.726\n"
     ]
    }
   ],
   "source": [
    "X_test = df_test.drop(columns=[\"OUTPUT_LABEL\"]).values\n",
    "y_test = df_test['OUTPUT_LABEL'].values\n",
    "X_test_tf = scaler.transform(X_test)\n",
    "y_test_preds_random_Rus= gbc_random_Rus.best_estimator_.predict_proba(X_test_tf)[:, 1]\n",
    "test_report = print_report(y_test, y_test_preds_random_Rus, thresh)\n",
    "\n",
    "\n",
    "print(f\"Training Report:\\n\\t  AUC={train_report[0]:.3f}\\n\\t Accuracy={train_report[1]:.3f}\\n\\t Recall={train_report[2]:.3f}\\n\\t Precision={train_report[3]:.3f}\\n\\t F1={train_report[4]:.3f}\")\n",
    "print(f\"Validation Report:\\n\\t  AUC={valid_report[0]:.3f}\\n\\t Accuracy={valid_report[1]:.3f}\\n\\t Recall={valid_report[2]:.3f}\\n\\t Precision={valid_report[3]:.3f}\\n\\t F1={valid_report[4]:.3f}\")\n",
    "print(\"test dataframe has been resampled using the same method as the training data\")\n",
    "print(f\"Test Report:\\n\\t  AUC={test_report[0]:.3f}\\n\\t Accuracy={test_report[1]:.3f}\\n\\t Recall={test_report[2]:.3f}\\n\\t Precision={test_report[3]:.3f}\\n\\t F1={test_report[4]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataframe has not been resampled\n",
      "Test Report:\n",
      "\t  AUC=0.801\n",
      "\t Accuracy=0.820\n",
      "\t Recall=0.660\n",
      "\t Precision=0.358\n",
      "\t F1=0.464\n"
     ]
    }
   ],
   "source": [
    "df_valid, df_test = train_test_split(df_valid_test, test_size=0.5, random_state=42)\n",
    "df_test = balance_data(df_test, balancer_type='None')\n",
    "print(\"Test dataframe has not been resampled\")\n",
    "X_test = df_test.drop(columns=[\"OUTPUT_LABEL\"]).values\n",
    "y_test = df_test['OUTPUT_LABEL'].values\n",
    "X_test_tf = scaler.transform(X_test)\n",
    "y_test_preds_random = gbc_random_smote.best_estimator_.predict_proba(X_test_tf)[:, 1]\n",
    "test_report = print_report(y_test, y_test_preds_random, thresh)\n",
    "print(f\"Test Report:\\n\\t  AUC={test_report[0]:.3f}\\n\\t Accuracy={test_report[1]:.3f}\\n\\t Recall={test_report[2]:.3f}\\n\\t Precision={test_report[3]:.3f}\\n\\t F1={test_report[4]:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
